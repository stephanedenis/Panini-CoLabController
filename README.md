# Module Colab Controller

**Status**: ğŸš§ En dÃ©veloppement actif  
**PrioritÃ©**: â­â­â­ Haute (Abonnement Colab Pro disponible)  
**DerniÃ¨re mise Ã  jour**: 2025-11-12

> **Note de migration (2025-08-30)**: Ce module sera fusionnÃ© avec `modules/cloud-orchestrator` dans `ExecutionOrchestrator` (drivers: local, colab, cloud). Voir `ARCHITECTURE/ADR-2025-08-30-modular-restructuring-option-b.md`.
>
> **Mise Ã  jour (2025-11-12)**: Priorisation Ã©levÃ©e suite Ã  disponibilitÃ© **Google Colab Pro** - GPU prioritaire, RAM Ã©tendue, sessions 24h. Voir `copilotage/knowledge/RESSOURCES_CLOUD_DISPONIBLES.md` pour stratÃ©gie d'utilisation.

## ğŸ¯ Mission

Orchestrer et automatiser l'utilisation de **Google Colab Pro** pour maximiser l'efficacitÃ© des expÃ©rimentations de recherche sur le projet Panini.

## ğŸ Ressources Colab Pro Disponibles

### GPU Prioritaires
- **T4**: 16GB VRAM - Fine-tuning
- **P100**: 16GB VRAM - Training modÃ¨les moyens
- **V100**: 16GB VRAM - Haute performance
- **A100**: 40GB VRAM - ModÃ¨les larges (prioritaire mais rare)

### CapacitÃ©s Ã‰tendues
- **RAM**: Jusqu'Ã  32GB+ (vs 12GB gratuit)
- **Session**: 24h continues (vs 12h gratuit)
- **AccÃ¨s**: Prioritaire lors de forte demande

## ğŸ“‹ FonctionnalitÃ©s Cibles

### Phase 1: Automation de Base â­ PRIORITAIRE
- [ ] **Lancement automatique** de notebooks depuis local
- [ ] **Gestion de queue** de jobs (sÃ©quentiel/parallÃ¨le)
- [ ] **Monitoring GPU**: dÃ©tection type, utilisation VRAM
- [ ] **RÃ©cupÃ©ration automatique** des rÃ©sultats vers local/Drive
- [ ] **Logging centralisÃ©** des exÃ©cutions

### Phase 2: Pipeline ML
- [ ] **Templates standardisÃ©s** par type d'expÃ©rimentation
- [ ] **Checkpointing automatique** toutes les N minutes
- [ ] **Gestion d'erreurs** et retry automatique
- [ ] **Snapshot Ã©tat GPU** avant crash
- [ ] **Cost tracking** (temps GPU utilisÃ© vs quota)

### Phase 3: IntÃ©gration Advanced
- [ ] **CI/CD**: Git push â†’ Auto-test sur Colab
- [ ] **Dashboard temps rÃ©el**: Monitoring multi-notebooks
- [ ] **Optimization scheduler**: Allocation intelligente des ressources
- [ ] **Notebook versioning**: Sync avec Git
- [ ] **Collaborative mode**: Partage de sessions

## ğŸ—ï¸ Architecture ProposÃ©e

```
modules/orchestration/colab/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ launcher.py          # Lance notebooks sur Colab
â”‚   â”œâ”€â”€ monitor.py           # Surveille exÃ©cutions
â”‚   â”œâ”€â”€ queue_manager.py     # GÃ¨re file d'attente
â”‚   â”œâ”€â”€ result_collector.py  # RÃ©cupÃ¨re outputs
â”‚   â””â”€â”€ templates/           # Notebooks prÃ©-configurÃ©s
â”‚       â”œâ”€â”€ training_template.ipynb
â”‚       â”œâ”€â”€ analysis_template.ipynb
â”‚       â””â”€â”€ validation_template.ipynb
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ colab_credentials.json  (git-ignored)
â”‚   â””â”€â”€ execution_config.yaml
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ execution_history.jsonl
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_launcher.py
â””â”€â”€ docs/
    â”œâ”€â”€ SETUP.md
    â””â”€â”€ API.md
```

## ğŸš€ Use Cases Panini

### 1. Optimisation Dictionnaire Panlang
```python
# Workflow automatisÃ© pour hillclimbing 10000+ itÃ©rations
from colab_controller import launch_notebook, monitor

job = launch_notebook(
    notebook='panlang_hillclimbing.ipynb',
    params={'iterations': 10000, 'checkpoint_freq': 100},
    gpu_required='V100',
    timeout_hours=20
)

results = monitor(job, callback=save_checkpoints)
```

### 2. Analyse Corpus Multilingue
```python
# Traitement parallÃ¨le sur plusieurs notebooks
jobs = []
for corpus in ['fr', 'en', 'es', 'de', 'sanskrit', 'chinois']:
    job = launch_notebook(
        notebook='corpus_analysis.ipynb',
        params={'language': corpus, 'dataset': f'corpus_{corpus}.json'},
        gpu_required='T4'
    )
    jobs.append(job)

results = wait_all(jobs)
merge_results(results, output='multilingual_analysis.json')
```

### 3. EntraÃ®nement Embeddings SÃ©mantiques
```python
# Pipeline complet avec backup automatique vers Google One
job = launch_notebook(
    notebook='train_embeddings.ipynb',
    params={
        'model': 'sentence-transformers',
        'corpus': 'gs://panini-datasets/semantic_corpus.json',
        'epochs': 50,
        'primitives': 'NSM'  # Natural Semantic Metalanguage
    },
    gpu_required='A100',  # Prioritaire si disponible
    auto_backup_to='gdrive:Panini/models/embeddings/',
    checkpoint_freq_minutes=30
)
```

## ğŸ“ Template Notebook Standard

Chaque notebook Panini devrait inclure ce header:

```python
# === PANINI COLAB STANDARD HEADER ===
import os
import sys
from pathlib import Path
from google.colab import drive
import torch
import json
import pickle
from datetime import datetime

# Montage Drive (Google One)
drive.mount('/content/drive')
PANINI_ROOT = Path('/content/drive/MyDrive/Panini')
sys.path.insert(0, str(PANINI_ROOT))

# VÃ©rification GPU
gpu_name = torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'
vram_gb = torch.cuda.get_device_properties(0).total_memory / 1e9 if torch.cuda.is_available() else 0
print(f"ğŸ¯ GPU: {gpu_name}")
print(f"ğŸ“Š VRAM: {vram_gb:.2f} GB")
print(f"ğŸ’¾ RAM: {psutil.virtual_memory().total / 1e9:.2f} GB")

# Logging automatique
log_dir = PANINI_ROOT / 'logs' / 'colab_executions'
log_dir.mkdir(parents=True, exist_ok=True)
log_file = log_dir / f"{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

# Checkpoint automatique
def save_checkpoint(data, name='checkpoint'):
    checkpoint_dir = PANINI_ROOT / 'checkpoints' / name
    checkpoint_dir.mkdir(parents=True, exist_ok=True)
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    path = checkpoint_dir / f"{timestamp}.pkl"
    with open(path, 'wb') as f:
        pickle.dump(data, f)
    print(f"âœ… Checkpoint sauvegardÃ©: {path}")

# === VOTRE CODE ICI ===
```

## ğŸ”§ Configuration Requise

### Installation
```bash
pip install google-colab-controller google-auth google-api-python-client
```

### Credentials
1. CrÃ©er OAuth 2.0 credentials sur Google Cloud Console
2. Activer Colab API
3. Stocker dans `config/colab_credentials.json` (git-ignored)

### Variables d'environnement
```bash
export GOOGLE_COLAB_CREDENTIALS=/path/to/credentials.json
export GOOGLE_DRIVE_ROOT=/content/drive/MyDrive/Panini
export PANINI_BACKUP_BUCKET=gs://panini-research-backup
```

## ğŸ¯ PrioritÃ©s de DÃ©veloppement

### Sprint 1 (Semaine 1-2): MVP â­ URGENT
1. âœ… Documentation des ressources disponibles
2. [ ] Script Python basique pour lancer un notebook via API
3. [ ] Monitoring simple (status: running/completed/failed)
4. [ ] RÃ©cupÃ©ration rÃ©sultats depuis Drive

### Sprint 2 (Semaine 3-4): Automation
5. [ ] Queue manager pour jobs multiples
6. [ ] Templates standardisÃ©s (3 types: training, analysis, validation)
7. [ ] Logging centralisÃ© dans `copilotage/journal/`

### Sprint 3 (Mois 2): Production
8. [ ] Dashboard web monitoring
9. [ ] CI/CD integration
10. [ ] Cost optimization et tracking quota

## ğŸ“š RÃ©fÃ©rences

- **Abonnements**: Voir `copilotage/knowledge/RESSOURCES_CLOUD_DISPONIBLES.md`
- [Colab Pro Features](https://colab.research.google.com/signup)
- [Google Colab API (unofficiel)](https://github.com/googlecolab/colabtools)
- [Best Practices](https://research.google.com/colaboratory/faq.html)
- **Architecture**: Voir `ARCHITECTURE_STANDARD.md`

## ğŸ¤ Contribution

Pour contribuer Ã  ce module:
1. CrÃ©er issue avec tag `colab-controller`
2. Branche: `feature/colab-{feature-name}`
3. Tests requis avant PR
4. Documentation Ã  jour dans `docs/`

---

**Maintenu par**: Ã‰quipe Infrastructure Panini  
**Contact**: Voir `docs/PROJECT_OVERVIEW.md`
